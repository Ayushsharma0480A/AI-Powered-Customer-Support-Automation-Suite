ğŸš€ Hive Assignment

Author: Ayush Sharma

ğŸ“¦ Components

Part A â€” Email Tagging Mini-System

Part B â€” Sentiment Analysis Prompt Evaluation

Part C â€” Mini-RAG for Knowledge Base Answering

ğŸ§© Part A â€” Email Tagging Mini-System
1ï¸âƒ£ Approach

LLM-based classification using GPT-4o-mini

Inputs combined: subject + body

Classifier restricted to customer-specific tags only

Output format:

{ "tag": "...", "reason": "..." }

2ï¸âƒ£ Ensuring Customer Isolation

A dictionary is created:

customer_id â†’ allowed_tags


For each email:

Only tags belonging to that customer are allowed

Prevents cross-customer tag leakage

LLM prompt strictly enforces allowed_tags

3ï¸âƒ£ Prompt Used
You are an email classifier. Choose exactly one tag from the allowed list.

Allowed tags: {tag_list}

Email Subject:
{subject}

Email Body:
{body}

Return ONLY valid JSON:
{
  "tag": "<one_of_allowed_tags>",
  "reason": "<short_reason>"
}

4ï¸âƒ£ Error Analysis

Common issues identified:

Issue	Cause	Fix
Generic words misleading the model	â€œpaymentâ€, â€œurgentâ€ appearing in many emails	Add phrase-level patterns
Politeness noise	â€œthanksâ€, â€œpleaseâ€	Instruct model to ignore courtesy phrases
Ambiguous complaints	â€œemail not workingâ€ matches multiple tags	Add context-heavy rules
5ï¸âƒ£ Improvements (Production)

Add lightweight rule-based filters

Use customer-specific embeddings

Add human feedback loop for progressively improving accuracy

ğŸ’¬ Part B â€” Sentiment Analysis Prompt Evaluation
1ï¸âƒ£ Prompt V1 (Initial)

Correctly classified all 10 emails

âŒ 40% responses wrapped inside ```json markdown blocks

âŒ Confidence inconsistent

2ï¸âƒ£ Summary of V1 Results

Accuracy: 100%

Formatting problems: markdown wrapping

Neutral vs negative: sometimes inconsistent

Confidence: varied too widely

3ï¸âƒ£ Improved Prompt V2 (Final)
You are a strict sentiment classifier.

Rules:
- Never return markdown or codeblocks.
- Return ONLY valid JSON.
- Frustration, urgency, anger â†’ negative
- Appreciation, satisfaction â†’ positive
- Simple questions without emotion â†’ neutral
- Mixed emotions â†’ neutral

Return:
{
  "sentiment": "...",
  "confidence": ...,
  "internal_reasoning": "..."
}

Email:
{email}

4ï¸âƒ£ What Failed in V1

Codeblock-wrapped JSON

Loose emotional interpretation

Non-standard confidence ranges

5ï¸âƒ£ What Improved in V2

Forced JSON-only output

Deterministic confidence ranges

Clear emotional classification rules

Higher consistency

6ï¸âƒ£ How to Evaluate Prompts Systematically

Test with 10â€“50 diverse emails

Validate JSON structure

Compare prompts (A/B test)

Include edge cases (polite but angry, mixed sentiment)

Check stability under paraphrasing

ğŸ“š Part C â€” Mini-RAG for Knowledge Base Answering
1ï¸âƒ£ Approach

Load KB files (.txt)

Extract embeddings using all-mpnet-base-v2

Build a FAISS L2 index

Retrieve top-k documents

Pass retrieved snippets to LLM for answer

Confidence = 1 - normalized_distance

2ï¸âƒ£ Query Results
ğŸ” Query 1: â€œHow do I configure automations in Hiver?â€

Top Retrieved:

article1.txt

article5.txt

article4.txt

Generated Answer:

Go to Admin â†’ Automations â†’ Create Rule â†’ Add Conditions â†’ Add Actions â†’ Enable.

Confidence: ~0.85

ğŸ” Query 2: â€œWhy is CSAT not appearing?â€

Top Retrieved:

article2.txt

article5.txt

article3.txt

Answer:

CSAT may be disabled or waiting to sync. Enable it under Admin â†’ CSAT.

Confidence: ~0.78

3ï¸âƒ£ Five Improvements

Chunk long documents (256â€“512 tokens)

Hybrid search (BM25 + embeddings)

Cross-encoder re-ranking

Metadata filtering (automation, analytics, auth)

Train domain-specific embeddings

4ï¸âƒ£ Failure Case

Query: â€œWhy are my emails delayed?â€
Issue: KB did not contain â€œdelayâ€ topic â†’ retrieval irrelevant.
Fix:

Add missing KB topics

Expand synonyms (lag, slow, stuck)

Hybrid lexical + semantic search

â–¶ï¸ How to Run
pip install -r requirements.txt

# Part A
python src/classifier.py

# Part B
python src/sentiment_prompt_test.py

# Part C
python src/rag.py

ğŸ“‚ Folder Structure
hiver-assignment/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classifier.py
â”‚   â”œâ”€â”€ sentiment_prompt_test.py
â”‚   â””â”€â”€ rag.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ emails.csv
â”‚   â”œâ”€â”€ sentiment_test_emails.txt
â”‚   â””â”€â”€ kb_articles/
â”‚       â”œâ”€â”€ article1.txt
â”‚       â”œâ”€â”€ article2.txt
â”‚       â”œâ”€â”€ article3.txt
â”‚       â”œâ”€â”€ article4.txt
â”‚       â”œâ”€â”€ article5.txt